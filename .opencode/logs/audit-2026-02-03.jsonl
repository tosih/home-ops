{"timestamp":"2026-02-03T06:19:59.652Z","event":"bash","command":"kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph status"}
{"timestamp":"2026-02-03T06:20:00.233Z","event":"bash","command":"kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph osd tree"}
{"timestamp":"2026-02-03T06:20:01.350Z","event":"bash","command":"kubectl -n rook-ceph get pods -l app=rook-ceph-osd | grep osd-1"}
{"timestamp":"2026-02-03T06:20:02.003Z","event":"bash","command":"kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph osd status"}
{"timestamp":"2026-02-03T06:20:12.042Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-64794ff647-tnzzc --all-containers --tail=100"}
{"timestamp":"2026-02-03T06:20:12.759Z","event":"bash","command":"kubectl -n rook-ceph describe pod rook-ceph-osd-1-64794ff647-tnzzc"}
{"timestamp":"2026-02-03T06:20:13.537Z","event":"bash","command":"kubectl -n rook-ceph get cephcluster -o yaml"}
{"timestamp":"2026-02-03T06:22:25.444Z","event":"bash","command":"kubectl -n rook-ceph scale deployment rook-ceph-osd-1 --replicas=0"}
{"timestamp":"2026-02-03T06:22:36.053Z","event":"bash","command":"kubectl -n rook-ceph run bluestore-repair --image=quay.io/ceph/ceph:v19.2.3 --restart=Never --overrides='\n{\n  \"spec\": {\n    \"nodeSelector\": {\n      \"kubernetes.io/hostname\": \"worker1\"\n    },\n    \"containers\": [{\n      \"name\": \"repair\",\n      \"image\": \"quay.io/ceph/ceph:v19.2.3\",\n      \"command\": [\"sleep\", \"3600\"],\n      \"securityContext\": {\n        \"privileged\": true\n      },\n      \"volumeMounts\": [{\n        \"name\": \"dev\",\n        \"mountPath\": \"/dev\"\n      }]\n    }],\n    \"volumes\": [{\n      \"name\": \"dev\",\n      \"hostPath\": {\n        \"path\": \"/dev\"\n      }\n    }]\n  }\n}'"}
{"timestamp":"2026-02-03T06:22:40.937Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=ready pod/bluestore-repair --timeout=60s"}
{"timestamp":"2026-02-03T06:22:47.681Z","event":"bash","command":"kubectl -n rook-ceph exec -it bluestore-repair -- ceph-bluestore-tool fsck --path /dev/sda"}
{"timestamp":"2026-02-03T06:22:54.507Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ls -la /dev/sd*"}
{"timestamp":"2026-02-03T06:22:58.268Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ls -la /dev/ | grep -E \"sd|nvme\""}
{"timestamp":"2026-02-03T06:23:03.510Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ceph-bluestore-tool fsck --path /dev/sda --deep"}
{"timestamp":"2026-02-03T06:23:07.506Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ceph-bluestore-tool fsck --path /dev/sda"}
{"timestamp":"2026-02-03T06:23:13.054Z","event":"bash","command":"kubectl -n rook-ceph get deployment rook-ceph-osd-1 -o yaml | grep -A 20 \"volumeMounts:\" | head -30"}
{"timestamp":"2026-02-03T06:23:18.239Z","event":"bash","command":"kubectl -n rook-ceph delete pod bluestore-repair --wait=true"}
{"timestamp":"2026-02-03T06:23:56.904Z","event":"bash","command":"kubectl -n rook-ceph run bluestore-repair --image=quay.io/ceph/ceph:v19.2.3 --restart=Never --overrides='\n{\n  \"spec\": {\n    \"nodeSelector\": {\n      \"kubernetes.io/hostname\": \"worker1\"\n    },\n    \"containers\": [{\n      \"name\": \"repair\",\n      \"image\": \"quay.io/ceph/ceph:v19.2.3\",\n      \"command\": [\"sleep\", \"3600\"],\n      \"securityContext\": {\n        \"privileged\": true\n      },\n      \"volumeMounts\": [\n        {\n          \"name\": \"dev\",\n          \"mountPath\": \"/dev\"\n        },\n        {\n          \"name\": \"var-lib-rook\",\n          \"mountPath\": \"/var/lib/rook\"\n        }\n      ]\n    }],\n    \"volumes\": [\n      {\n        \"name\": \"dev\",\n        \"hostPath\": {\n          \"path\": \"/dev\"\n        }\n      },\n      {\n        \"name\": \"var-lib-rook\",\n        \"hostPath\": {\n          \"path\": \"/var/lib/rook\"\n        }\n      }\n    ]\n  }\n}'"}
{"timestamp":"2026-02-03T06:24:00.610Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=ready pod/bluestore-repair --timeout=60s"}
{"timestamp":"2026-02-03T06:24:04.633Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ls -la /var/lib/rook/"}
{"timestamp":"2026-02-03T06:24:10.821Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ls -la /var/lib/rook/storage/"}
{"timestamp":"2026-02-03T06:24:15.470Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- find /var/lib/rook -name \"*osd*\" -o -name \"ceph-1\" 2>/dev/null"}
{"timestamp":"2026-02-03T06:24:22.674Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ls -la /var/lib/rook/rook-ceph/082d1c99-3c5f-4524-af39-ea9ab0d5cc9e_2c3b6ce0-bc49-42a7-9ac4-06adba397860/"}
{"timestamp":"2026-02-03T06:24:29.585Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- ceph-bluestore-tool fsck --path /var/lib/rook/rook-ceph/082d1c99-3c5f-4524-af39-ea9ab0d5cc9e_2c3b6ce0-bc49-42a7-9ac4-06adba397860"}
{"timestamp":"2026-02-03T06:25:46.987Z","event":"bash","command":"kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph osd out 1"}
{"timestamp":"2026-02-03T06:25:55.990Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd tree"}
{"timestamp":"2026-02-03T06:26:09.891Z","event":"bash","command":"kubectl -n rook-ceph delete deployment rook-ceph-osd-1"}
{"timestamp":"2026-02-03T06:26:17.731Z","event":"bash","command":"kubectl -n rook-ceph get job | grep \"rook-ceph-osd-prepare.*worker1\""}
{"timestamp":"2026-02-03T06:26:21.652Z","event":"bash","command":"kubectl -n rook-ceph delete job rook-ceph-osd-prepare-worker1"}
{"timestamp":"2026-02-03T06:26:32.074Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- sgdisk --zap-all /dev/sda"}
{"timestamp":"2026-02-03T06:26:38.087Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- dd if=/dev/zero of=/dev/sda bs=1M count=100"}
{"timestamp":"2026-02-03T06:26:45.974Z","event":"bash","command":"kubectl -n rook-ceph exec bluestore-repair -- rm -rf /var/lib/rook/rook-ceph/082d1c99-3c5f-4524-af39-ea9ab0d5cc9e_2c3b6ce0-bc49-42a7-9ac4-06adba397860"}
{"timestamp":"2026-02-03T06:27:01.206Z","event":"bash","command":"kubectl -n rook-ceph delete pod bluestore-repair --wait=true"}
{"timestamp":"2026-02-03T06:27:38.298Z","event":"bash","command":"kubectl -n rook-ceph rollout restart deployment rook-ceph-operator"}
{"timestamp":"2026-02-03T06:27:48.297Z","event":"bash","command":"sleep 10 && kubectl -n rook-ceph get pods -l app=rook-ceph-osd"}
{"timestamp":"2026-02-03T06:28:03.404Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-58c988b566-clrk5 -c provision --tail=50"}
{"timestamp":"2026-02-03T06:28:07.625Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-58c988b566-clrk5 -c blkdevmapper --tail=100"}
{"timestamp":"2026-02-03T06:28:11.694Z","event":"bash","command":"kubectl -n rook-ceph get pod rook-ceph-osd-1-58c988b566-clrk5 -o jsonpath='{.spec.initContainers[*].name}'"}
{"timestamp":"2026-02-03T06:28:16.312Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-58c988b566-clrk5 -c activate --tail=100"}
{"timestamp":"2026-02-03T06:28:23.973Z","event":"bash","command":"kubectl -n rook-ceph get pod rook-ceph-osd-1-58c988b566-clrk5"}
{"timestamp":"2026-02-03T06:28:28.987Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-58c988b566-clrk5 -c expand-bluefs --tail=100"}
{"timestamp":"2026-02-03T06:28:36.989Z","event":"bash","command":"kubectl -n rook-ceph scale deployment rook-ceph-osd-1 --replicas=0"}
{"timestamp":"2026-02-03T06:28:39.557Z","event":"bash","command":"kubectl -n rook-ceph run disk-wiper --image=quay.io/ceph/ceph:v19.2.3 --restart=Never --overrides='\n{\n  \"spec\": {\n    \"nodeSelector\": {\n      \"kubernetes.io/hostname\": \"worker1\"\n    },\n    \"containers\": [{\n      \"name\": \"wiper\",\n      \"image\": \"quay.io/ceph/ceph:v19.2.3\",\n      \"command\": [\"sleep\", \"3600\"],\n      \"securityContext\": {\n        \"privileged\": true\n      },\n      \"volumeMounts\": [{\n        \"name\": \"dev\",\n        \"mountPath\": \"/dev\"\n      }]\n    }],\n    \"volumes\": [{\n      \"name\": \"dev\",\n      \"hostPath\": {\n        \"path\": \"/dev\"\n      }\n    }]\n  }\n}'"}
{"timestamp":"2026-02-03T06:28:47.709Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=ready pod/disk-wiper --timeout=60s"}
{"timestamp":"2026-02-03T06:28:52.917Z","event":"bash","command":"kubectl -n rook-ceph exec disk-wiper -- wipefs --all /dev/sda"}
{"timestamp":"2026-02-03T06:28:57.827Z","event":"bash","command":"kubectl -n rook-ceph exec disk-wiper -- dd if=/dev/zero of=/dev/sda bs=1M count=500 status=progress"}
{"timestamp":"2026-02-03T06:29:04.150Z","event":"bash","command":"kubectl -n rook-ceph exec disk-wiper -- sh -c 'DISK_SIZE=$(blockdev --getsize64 /dev/sda); dd if=/dev/zero of=/dev/sda bs=1M seek=$((DISK_SIZE/1048576 - 500)) count=500'"}
{"timestamp":"2026-02-03T06:29:10.775Z","event":"bash","command":"kubectl -n rook-ceph delete pod disk-wiper --wait=true"}
{"timestamp":"2026-02-03T06:29:11.355Z","event":"bash","command":"kubectl -n rook-ceph rollout restart deployment rook-ceph-operator"}
{"timestamp":"2026-02-03T06:30:00.322Z","event":"bash","command":"kubectl -n rook-ceph run disk-check --image=quay.io/ceph/ceph:v19.2.3 --restart=Never --overrides='\n{\n  \"spec\": {\n    \"nodeSelector\": {\n      \"kubernetes.io/hostname\": \"worker1\"\n    },\n    \"containers\": [{\n      \"name\": \"check\",\n      \"image\": \"quay.io/ceph/ceph:v19.2.3\",\n      \"command\": [\"sleep\", \"300\"],\n      \"securityContext\": {\n        \"privileged\": true\n      },\n      \"volumeMounts\": [{\n        \"name\": \"dev\",\n        \"mountPath\": \"/dev\"\n      }]\n    }],\n    \"volumes\": [{\n      \"name\": \"dev\",\n      \"hostPath\": {\n        \"path\": \"/dev\"\n      }\n    }]\n  }\n}'"}
{"timestamp":"2026-02-03T06:30:05.868Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=ready pod/disk-check --timeout=30s && kubectl -n rook-ceph exec disk-check -- lsblk -b /dev/sda"}
{"timestamp":"2026-02-03T06:30:13.498Z","event":"bash","command":"kubectl -n rook-ceph exec disk-check -- lsblk -o NAME,SIZE,TYPE,MOUNTPOINT"}
{"timestamp":"2026-02-03T06:30:19.158Z","event":"bash","command":"kubectl -n rook-ceph delete pod disk-check --wait=true"}
{"timestamp":"2026-02-03T06:30:19.898Z","event":"bash","command":"kubectl -n rook-ceph get pods -l app=rook-ceph-osd"}
{"timestamp":"2026-02-03T06:30:55.520Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-64794ff647-fgx26 -c activate --tail=50"}
{"timestamp":"2026-02-03T06:31:04.178Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd purge 1 --yes-i-really-mean-it"}
{"timestamp":"2026-02-03T06:31:09.975Z","event":"bash","command":"kubectl -n rook-ceph delete deployment rook-ceph-osd-1 --ignore-not-found"}
{"timestamp":"2026-02-03T06:31:10.692Z","event":"bash","command":"kubectl -n rook-ceph delete configmap rook-ceph-osd-1-config --ignore-not-found"}
{"timestamp":"2026-02-03T06:31:11.639Z","event":"bash","command":"kubectl -n rook-ceph get job | grep worker1 | awk '{print $1}' | xargs -r kubectl -n rook-ceph delete job"}
{"timestamp":"2026-02-03T06:31:17.422Z","event":"bash","command":"kubectl -n rook-ceph rollout restart deployment rook-ceph-operator && sleep 15 && kubectl -n rook-ceph get pods -l app=rook-ceph-osd"}
{"timestamp":"2026-02-03T06:31:39.041Z","event":"bash","command":"kubectl -n rook-ceph logs -l app=rook-ceph-operator --tail=50 --since=30s | grep -i \"worker1\\|osd.*1\\|device.*sda\" | head -20"}
{"timestamp":"2026-02-03T06:31:45.261Z","event":"bash","command":"kubectl -n rook-ceph get cephblocknodedrain,cephb lockpooldisrupt"}
{"timestamp":"2026-02-03T06:31:51.369Z","event":"bash","command":"kubectl -n rook-ceph get cephcluster rook-ceph -o jsonpath='{.status.ceph.osd}' | jq"}
{"timestamp":"2026-02-03T06:31:56.672Z","event":"bash","command":"sleep 30 && kubectl -n rook-ceph get jobs | grep worker1"}
{"timestamp":"2026-02-03T06:32:32.008Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=complete job/rook-ceph-osd-prepare-worker1 --timeout=300s"}
{"timestamp":"2026-02-03T06:32:40.124Z","event":"bash","command":"kubectl -n rook-ceph get pods -l app=rook-ceph-osd"}
{"timestamp":"2026-02-03T06:32:46.711Z","event":"bash","command":"kubectl -n rook-ceph logs rook-ceph-osd-1-58c988b566-b8z6c -c activate --tail=100"}
{"timestamp":"2026-02-03T06:36:49.811Z","event":"bash","command":"kubectl -n rook-ceph run ceph-zap --image=quay.io/ceph/ceph:v19.2.3 --restart=Never --overrides='\n{\n  \"spec\": {\n    \"nodeSelector\": {\n      \"kubernetes.io/hostname\": \"worker1\"\n    },\n    \"containers\": [{\n      \"name\": \"zap\",\n      \"image\": \"quay.io/ceph/ceph:v19.2.3\",\n      \"command\": [\"sleep\", \"300\"],\n      \"securityContext\": {\n        \"privileged\": true\n      },\n      \"volumeMounts\": [{\n        \"name\": \"dev\",\n        \"mountPath\": \"/dev\"\n      }]\n    }],\n    \"volumes\": [{\n      \"name\": \"dev\",\n      \"hostPath\": {\n        \"path\": \"/dev\"\n      }\n    }]\n  }\n}'"}
{"timestamp":"2026-02-03T06:36:54.683Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=ready pod/ceph-zap --timeout=30s"}
{"timestamp":"2026-02-03T06:36:55.720Z","event":"bash","command":"kubectl -n rook-ceph exec ceph-zap -- ceph-volume raw zap /dev/sda"}
{"timestamp":"2026-02-03T06:37:02.011Z","event":"bash","command":"kubectl -n rook-ceph exec ceph-zap -- ceph-volume lvm zap /dev/sda --destroy"}
{"timestamp":"2026-02-03T06:37:15.754Z","event":"bash","command":"kubectl -n rook-ceph exec ceph-zap -- ceph-volume raw list /dev/sda"}
{"timestamp":"2026-02-03T06:37:21.387Z","event":"bash","command":"kubectl -n rook-ceph delete pod ceph-zap --wait=true"}
{"timestamp":"2026-02-03T06:37:22.189Z","event":"bash","command":"kubectl -n rook-ceph delete deployment rook-ceph-osd-1 --ignore-not-found"}
{"timestamp":"2026-02-03T06:37:23.332Z","event":"bash","command":"kubectl -n rook-ceph delete job rook-ceph-osd-prepare-worker1 --ignore-not-found"}
{"timestamp":"2026-02-03T06:37:23.937Z","event":"bash","command":"kubectl -n rook-ceph rollout restart deployment rook-ceph-operator"}
{"timestamp":"2026-02-03T06:37:57.127Z","event":"bash","command":"sleep 30 && kubectl -n rook-ceph get jobs | grep worker1"}
{"timestamp":"2026-02-03T06:38:33.173Z","event":"bash","command":"kubectl -n rook-ceph logs -l app=rook-ceph-operator --tail=30 --since=1m | grep -i \"worker1\\|device.*sda\\|osd\""}
{"timestamp":"2026-02-03T06:38:38.597Z","event":"bash","command":"kubectl -n rook-ceph get jobs,pods | grep worker1"}
{"timestamp":"2026-02-03T06:38:43.225Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=complete job/rook-ceph-osd-prepare-worker1 --timeout=300s"}
{"timestamp":"2026-02-03T06:40:49.131Z","event":"bash","command":"kubectl -n rook-ceph logs job/rook-ceph-osd-prepare-worker1 --tail=50"}
{"timestamp":"2026-02-03T06:40:58.083Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph auth del osd.1"}
{"timestamp":"2026-02-03T06:40:58.890Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd crush remove osd.1"}
{"timestamp":"2026-02-03T06:40:59.555Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd rm 1"}
{"timestamp":"2026-02-03T06:41:10.620Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph auth ls | grep -A 5 \"osd.1\""}
{"timestamp":"2026-02-03T06:41:16.160Z","event":"bash","command":"kubectl -n rook-ceph delete job rook-ceph-osd-prepare-worker1"}
{"timestamp":"2026-02-03T06:41:16.947Z","event":"bash","command":"kubectl -n rook-ceph rollout restart deployment rook-ceph-operator"}
{"timestamp":"2026-02-03T06:41:21.552Z","event":"bash","command":"sleep 30 && kubectl -n rook-ceph get jobs | grep worker1"}
{"timestamp":"2026-02-03T06:41:57.667Z","event":"bash","command":"kubectl -n rook-ceph logs -l app=rook-ceph-operator --tail=50 --since=1m | grep -E \"worker1|osd.*1\""}
{"timestamp":"2026-02-03T06:42:06.165Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd dump | grep -E \"^osd\\.|^max_osd\""}
{"timestamp":"2026-02-03T06:42:06.751Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph status"}
{"timestamp":"2026-02-03T06:42:14.063Z","event":"bash","command":"kubectl -n rook-ceph get cephcluster rook-ceph -o jsonpath='{.spec.disruptionManagement}' | jq"}
{"timestamp":"2026-02-03T06:42:21.402Z","event":"bash","command":"kubectl -n rook-ceph patch cephcluster rook-ceph --type=merge -p '{\"spec\":{\"disruptionManagement\":{\"managePodBudgets\":false}}}'"}
{"timestamp":"2026-02-03T06:42:26.693Z","event":"bash","command":"sleep 20 && kubectl -n rook-ceph get jobs,pods | grep worker1"}
{"timestamp":"2026-02-03T06:42:56.368Z","event":"bash","command":"kubectl -n rook-ceph logs -f job/rook-ceph-osd-prepare-worker1 --tail=20"}
{"timestamp":"2026-02-03T06:43:02.454Z","event":"bash","command":"kubectl -n rook-ceph wait --for=condition=complete job/rook-ceph-osd-prepare-worker1 --timeout=300s"}
{"timestamp":"2026-02-03T06:43:07.443Z","event":"bash","command":"kubectl -n rook-ceph get pods -l app=rook-ceph-osd"}
{"timestamp":"2026-02-03T06:43:13.003Z","event":"bash","command":"kubectl -n rook-ceph logs -l app=rook-ceph-operator --tail=100 --since=2m | grep -E \"osd.*1|worker1\" | tail -20"}
{"timestamp":"2026-02-03T06:43:23.424Z","event":"bash","command":"sleep 30 && kubectl -n rook-ceph get deployments -l app=rook-ceph-osd"}
{"timestamp":"2026-02-03T06:43:58.755Z","event":"bash","command":"kubectl -n rook-ceph get pods -l ceph-osd-id=1"}
{"timestamp":"2026-02-03T06:44:04.319Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph osd tree"}
{"timestamp":"2026-02-03T06:44:04.853Z","event":"bash","command":"kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph status"}
{"timestamp":"2026-02-03T06:44:15.136Z","event":"bash","command":"kubectl -n rook-ceph patch cephcluster rook-ceph --type=merge -p '{\"spec\":{\"disruptionManagement\":{\"managePodBudgets\":true}}}'"}
{"timestamp":"2026-02-03T07:04:38.339Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/databases/cloudnative-pg/clusters/v17/postgres-cluster.yaml","oldLength":713,"newLength":136}
{"timestamp":"2026-02-03T07:04:44.031Z","event":"bash","command":"rm /Users/sohailahmed/Developer/home-ops/kubernetes/apps/databases/cloudnative-pg/clusters/v17/scheduled-backup.yaml"}
{"timestamp":"2026-02-03T07:04:45.439Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/databases/cloudnative-pg/clusters/v17/kustomization.yaml","oldLength":158,"newLength":130}
{"timestamp":"2026-02-03T07:04:51.823Z","event":"bash","command":"rm /Users/sohailahmed/Developer/home-ops/kubernetes/apps/rook-ceph/rook-ceph/cluster/objectbucketclaim-postgres.yaml /Users/sohailahmed/Developer/home-ops/kubernetes/apps/rook-ceph/rook-ceph/cluster/ceph-objectstore-user-postgres.yaml"}
{"timestamp":"2026-02-03T07:04:54.050Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/rook-ceph/rook-ceph/cluster/kustomization.yaml","oldLength":286,"newLength":206}
{"timestamp":"2026-02-03T07:07:15.447Z","event":"bash","command":"git show HEAD:kubernetes/apps/rook-ceph/rook-ceph/cluster/objectbucketclaim-postgres.yaml | grep -A 5 -B 5 \"reclaimPolicy\\|storageClassName\""}
{"timestamp":"2026-02-03T07:07:22.065Z","event":"bash","command":"kubectl get storageclass ceph-bucket -o yaml 2>/dev/null | grep reclaimPolicy || echo \"StorageClass not found or cluster not accessible\""}
{"timestamp":"2026-02-03T07:07:41.667Z","event":"bash","command":"git status"}
{"timestamp":"2026-02-03T07:07:42.153Z","event":"bash","command":"git diff"}
{"timestamp":"2026-02-03T07:07:42.644Z","event":"bash","command":"git log --oneline -10"}
{"timestamp":"2026-02-03T07:07:51.170Z","event":"bash","command":"git add kubernetes/apps/databases/cloudnative-pg/clusters/v17/kustomization.yaml kubernetes/apps/databases/cloudnative-pg/clusters/v17/postgres-cluster.yaml kubernetes/apps/databases/cloudnative-pg/clusters/v17/scheduled-backup.yaml kubernetes/apps/rook-ceph/rook-ceph/cluster/ceph-objectstore-user-postgres.yaml kubernetes/apps/rook-ceph/rook-ceph/cluster/kustomization.yaml kubernetes/apps/rook-ceph/rook-ceph/cluster/objectbucketclaim-postgres.yaml && git commit -m \"remove postgres backups and S3 bucket configuration\" && git status"}
{"timestamp":"2026-02-03T07:09:24.422Z","event":"bash","command":"git pull --rebase && git push"}
{"timestamp":"2026-02-03T07:13:01.492Z","event":"bash","command":"ls -la kubernetes/apps/kube-system/volsync/"}
{"timestamp":"2026-02-03T07:13:02.039Z","event":"bash","command":"ls -la kubernetes/apps/cloud/memos/backup/"}
{"timestamp":"2026-02-03T07:13:02.572Z","event":"bash","command":"ls -la kubernetes/apps/security/pocket-id/backup/"}
{"timestamp":"2026-02-03T07:13:18.955Z","event":"bash","command":"find kubernetes/apps -name \"ks.yaml\" -path \"*/backup/*\" 2>/dev/null"}
{"timestamp":"2026-02-03T07:13:19.661Z","event":"bash","command":"ls -la kubernetes/apps/cloud/memos/"}
{"timestamp":"2026-02-03T07:13:20.154Z","event":"bash","command":"ls -la kubernetes/apps/security/pocket-id/"}
{"timestamp":"2026-02-03T07:13:29.184Z","event":"bash","command":"rm -rf kubernetes/apps/kube-system/volsync"}
{"timestamp":"2026-02-03T07:13:31.687Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/kube-system/kustomization.yaml","oldLength":239,"newLength":217}
{"timestamp":"2026-02-03T07:13:37.459Z","event":"bash","command":"rm -rf kubernetes/apps/cloud/memos/backup"}
{"timestamp":"2026-02-03T07:13:42.387Z","event":"bash","command":"rm -rf kubernetes/apps/security/pocket-id/backup"}
{"timestamp":"2026-02-03T07:13:45.014Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/security/pocket-id/app/kustomization.yaml","oldLength":239,"newLength":225}
{"timestamp":"2026-02-03T07:13:51.371Z","event":"bash","command":"rm kubernetes/apps/rook-ceph/rook-ceph/cluster/objectbucketclaim-volsync.yaml kubernetes/apps/rook-ceph/rook-ceph/cluster/ceph-objectstore-user-volsync.yaml"}
{"timestamp":"2026-02-03T07:13:53.419Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/rook-ceph/rook-ceph/cluster/kustomization.yaml","oldLength":206,"newLength":128}
{"timestamp":"2026-02-03T07:14:01.188Z","event":"edit","file":"/Users/sohailahmed/Developer/home-ops/kubernetes/apps/rook-ceph/rook-ceph/cluster/kustomization.yaml","oldLength":206,"newLength":128}
{"timestamp":"2026-02-03T07:15:37.310Z","event":"bash","command":"git status"}
{"timestamp":"2026-02-03T07:15:37.903Z","event":"bash","command":"git diff --stat"}
{"timestamp":"2026-02-03T07:15:38.568Z","event":"bash","command":"git log --oneline -5"}
{"timestamp":"2026-02-03T07:15:43.666Z","event":"bash","command":"git add -A && git commit -m \"remove volsync operator and all backup configurations\" && git push"}
